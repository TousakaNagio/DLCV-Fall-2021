{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLCV_ViT_ver3",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e0f770111854b3b83479a92ea10817a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c24758198224a7d98c4b79184b40ea6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23a088f55b224676bf5c3aafeb87d0cb",
              "IPY_MODEL_316531ed121f47efa15eff607eb78150",
              "IPY_MODEL_8b00edb2dbdf4cb6b7ae270d68630613"
            ]
          }
        },
        "2c24758198224a7d98c4b79184b40ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23a088f55b224676bf5c3aafeb87d0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_781fc18d419648a196ce67db057bec40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1419c2cdacbe435ea11e3615c879ada8"
          }
        },
        "316531ed121f47efa15eff607eb78150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0955617e45504c59b6955ac0a6c78ea9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 347469964,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 347469964,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_88267959277a4f58ac764b5ffe890db3"
          }
        },
        "8b00edb2dbdf4cb6b7ae270d68630613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_13422e5c642c402d9aa0a4614723ac75",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:11&lt;00:00, 26.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_905bb8e3dffa4795806adff3f03b8d72"
          }
        },
        "781fc18d419648a196ce67db057bec40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1419c2cdacbe435ea11e3615c879ada8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0955617e45504c59b6955ac0a6c78ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "88267959277a4f58ac764b5ffe890db3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13422e5c642c402d9aa0a4614723ac75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "905bb8e3dffa4795806adff3f03b8d72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8PkFGc0_U3ZM",
        "outputId": "7965dfc9-ddc0-48d4-8e47-0e405f3b5f77"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Nov 28 17:44:21 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgxgMP_N4sNA",
        "outputId": "dea8f459-7f7c-4cbe-c4d2-e8429d0a0ff5"
      },
      "source": [
        "!gdown --id 1gakxwJjOa_lsT98_pmCFFEOYwzE43OLo --output \"data.zip\"\n",
        "!unzip -q \"data.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1gakxwJjOa_lsT98_pmCFFEOYwzE43OLo\n",
            "To: /content/data.zip\n",
            "100% 547M/547M [00:03<00:00, 151MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkT5YsXT9UMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f082e02-5346-4eb4-e185-e8c3a802f7a0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaPoNJ6JELiK",
        "outputId": "0cced307-2488-4c7c-bfbe-574d593f20df"
      },
      "source": [
        "! pip install pytorch_pretrained_vit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_pretrained_vit\n",
            "  Downloading pytorch-pretrained-vit-0.0.7.tar.gz (13 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_vit) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch_pretrained_vit) (3.10.0.2)\n",
            "Building wheels for collected packages: pytorch-pretrained-vit\n",
            "  Building wheel for pytorch-pretrained-vit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-pretrained-vit: filename=pytorch_pretrained_vit-0.0.7-py3-none-any.whl size=11131 sha256=10e8e7ce66fe57362fd2bdf9f3a16010ebb45d086210783366fcd322351d2efc\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/1d/d1/c6852ef6d18565e5aee866432ab40c6ffbd3411d592035cddb\n",
            "Successfully built pytorch-pretrained-vit\n",
            "Installing collected packages: pytorch-pretrained-vit\n",
            "Successfully installed pytorch-pretrained-vit-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ei_GNwlWAT1"
      },
      "source": [
        "! mkdir -p /content/checkpoint\n",
        "! cp -r /content/drive/MyDrive/DLCV/HW3/model13000.pth /content/checkpoint/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap9a0V85LiVK",
        "outputId": "c5ff7a2e-0ff3-4fed-a320-b8f092637625"
      },
      "source": [
        "!pip install transformers==4.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.5.0\n",
            "  Downloading transformers-4.5.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2.23.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 27.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 90.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.0) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.0) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.5.0) (3.0.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.0) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.0) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQg8jAKS_idW"
      },
      "source": [
        "##Import the package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOuBN0vM_h5r"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt2OQRgw_tlh"
      },
      "source": [
        "由於訓練過程中會有一些隨機性，為了確保每次重新訓練的情況下都可以得到同樣的結果，因此將random、torch、numpy三個套件的 random seed固定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDpJsoCP_o15"
      },
      "source": [
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def same_seeds(seed):\n",
        "    # Python built-in random module\n",
        "    random.seed(seed)\n",
        "    # Numpy\n",
        "    np.random.seed(seed)\n",
        "    # Torch\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "same_seeds(1126)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PorU1h4vJURt"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0W-k1c4BWf4"
      },
      "source": [
        "##MODEL\n",
        "這次的作業不會一定要同學重頭開始訓練，pytorch有內建在不同種資料集訓練的模型，有各種不同的方式可以載入預訓練好的模型，以下提供一個方法給同學，但需要注意的是同學最好還是要了解一下使用的模型架構，像是以Imagenet訓練的模型最後會輸出1000個值，但是這次的小資料集只需要分成50個類別，因此可能就需要做一些調整\n",
        "```\n",
        "import torchvision.models as models \n",
        "model = models.vgg16(pretrained=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDH0cLIKa4By"
      },
      "source": [
        "import torchvision.models as models\n",
        "from pytorch_pretrained_vit import ViT\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "      # TODO\n",
        "      super(Net, self).__init__()\n",
        "\n",
        "      # self.load_model = models.wide_resnet50_2(pretrained = True, progress=True)\n",
        "      self.load_model = ViT('B_16_imagenet1k', pretrained=True)\n",
        "      # print(self.load_model.image_size)\n",
        "      self.Layer = nn.Linear(1000, 37)\n",
        "      # self.resnet18.fc.out_features = 50\n",
        "\n",
        "    def forward(self, x):\n",
        "      # TODO \n",
        "      x = self.load_model(x)\n",
        "      x = self.Layer(x)\n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6e0f770111854b3b83479a92ea10817a",
            "2c24758198224a7d98c4b79184b40ea6",
            "23a088f55b224676bf5c3aafeb87d0cb",
            "316531ed121f47efa15eff607eb78150",
            "8b00edb2dbdf4cb6b7ae270d68630613",
            "781fc18d419648a196ce67db057bec40",
            "1419c2cdacbe435ea11e3615c879ada8",
            "0955617e45504c59b6955ac0a6c78ea9",
            "88267959277a4f58ac764b5ffe890db3",
            "13422e5c642c402d9aa0a4614723ac75",
            "905bb8e3dffa4795806adff3f03b8d72"
          ]
        },
        "id": "nyNpAnhpW5Mc",
        "outputId": "f173aa50-29b7-45cd-acb3-1bb00430e835"
      },
      "source": [
        "# \"cuda\" only when GPUs are available.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize a model, and put it on the device specified.\n",
        "model = Net().to(device)\n",
        "# state = torch.load('/content/checkpoint/model13000.pth')\n",
        "# model.load_state_dict(state['state_dict'])\n",
        "\n",
        "# model.device = device\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/lukemelas/PyTorch-Pretrained-ViT/releases/download/0.0.2/B_16_imagenet1k.pth\" to /root/.cache/torch/hub/checkpoints/B_16_imagenet1k.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e0f770111854b3b83479a92ea10817a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/331M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights.\n",
            "Net(\n",
            "  (load_model): ViT(\n",
            "    (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "    (positional_embedding): PositionalEmbedding1D()\n",
            "    (transformer): Transformer(\n",
            "      (blocks): ModuleList(\n",
            "        (0): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (1): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (2): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (3): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (4): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (5): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (6): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (7): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (8): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (9): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (10): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (11): Block(\n",
            "          (attn): MultiHeadedSelfAttention(\n",
            "            (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (drop): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (pwff): PositionWiseFeedForward(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          )\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (drop): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
            "  )\n",
            "  (Layer): Linear(in_features=1000, out_features=37, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwlwJXz0AcHN"
      },
      "source": [
        "##Dataset\n",
        "TODO\n",
        "\n",
        "可以參考之前提供的sample code 完成客製化的Dataset class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6DP0XYK30YI"
      },
      "source": [
        "train_tfm = transforms.Compose([\n",
        "    # Resize the image into a fixed shape (height = width = 128)\n",
        "    transforms.Resize((384, 384)),\n",
        "    # transforms.RandomVerticalFlip(p=0.3),\n",
        "    transforms.AutoAugment(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "])\n",
        "\n",
        "valid_tfm = transforms.Compose([\n",
        "    # Resize the image into a fixed shape (height = width = 128)\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.5, 0.5),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYJvPUv-cVWg"
      },
      "source": [
        "from PIL import Image\n",
        "from os import listdir,walk\n",
        "from os.path import join\n",
        "\n",
        "class IMAGE(Dataset):\n",
        "  def __init__(self,root,transform=None):\n",
        "    self.transform = transform\n",
        "    self.filenames = []\n",
        "    files = sorted(glob.glob(os.path.join(root, '*.jpg')), key = lambda x:(int(x.split('/')[-1].split('_')[0]), int(x.split('_')[-1].split('.')[0])))\n",
        "    # files = glob.glob(os.path.join(root, '*.png'))\n",
        "    # files = listdir(root)\n",
        "    for fn in files:\n",
        "      # print(fn)\n",
        "      head = fn.split('/')[5]\n",
        "      head = head.split('_')[0]\n",
        "      head = int(head)\n",
        "      self.filenames.append((fn, head))\n",
        "    self.len = len(self.filenames)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    image_fn,label = self.filenames[index]\n",
        "    image = Image.open(image_fn).convert('RGB')\n",
        "    # image = Image.open(image_fn)\n",
        "    if self.transform is not None:\n",
        "      # image = self.transform(image).unsqueeze(0)\n",
        "      image = self.transform(image)\n",
        "      # image = image.unsqueeze(0)\n",
        "    return image,label\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqQ9ZXoMdvYI",
        "outputId": "6db9e80f-7107-45c7-a9ab-94cb1707b767"
      },
      "source": [
        "train_set = IMAGE(root = '/content/hw3_data/p1_data/train',transform = train_tfm)\n",
        "valid_set = IMAGE(root = '/content/hw3_data/p1_data/val',transform = valid_tfm)\n",
        "\n",
        "a,b = valid_set[68]\n",
        "print(a.shape)\n",
        "\n",
        "print(len(train_set))\n",
        "print(len(valid_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 384, 384])\n",
            "3680\n",
            "1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp5wXemhtJPj",
        "outputId": "446b03a6-dd0a-480f-dd2c-96b6bb7e2fab"
      },
      "source": [
        "batch_size = 4\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=8, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe8sMdnxxtSI",
        "outputId": "a332de1c-88cb-4297-d85c-38f5337e139d"
      },
      "source": [
        "a,b = valid_set[1155]\n",
        "print(a.shape)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 384, 384])\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV9bt-usd1Iu",
        "outputId": "27f2301f-757c-4db2-a0b2-2c64a02baa3c"
      },
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3b0KzR_piFb"
      },
      "source": [
        "##Training function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOfAJJqAnjIF"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup, get_constant_schedule, get_cosine_schedule_with_warmup\n",
        "\n",
        "def save_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = {'state_dict': model.state_dict(),\n",
        "             'optimizer' : optimizer.state_dict()}\n",
        "    torch.save(state, checkpoint_path)\n",
        "    print('model saved to %s' % checkpoint_path)\n",
        "    \n",
        "def load_checkpoint(checkpoint_path, model, optimizer):\n",
        "    state = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(state['state_dict'])\n",
        "    optimizer.load_state_dict(state['optimizer'])\n",
        "    print('model loaded from %s' % checkpoint_path)\n",
        "\n",
        "def train_save(model, epoch, save_interval, log_interval=100):\n",
        "    # optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
        "    optimizer = optim.SGD(model.parameters(), lr = 0.0003, momentum = 0.9)\n",
        "    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.train()\n",
        "\n",
        "    max_steps = len(train_loader) / batch_size\n",
        "    # scheduler = get_linear_schedule_with_warmup(optimizer, 5, 20)\n",
        "    # scheduler = get_constant_schedule(optimizer)\n",
        "    scheduler = get_cosine_schedule_with_warmup(optimizer, 5, 20)\n",
        "    \n",
        "    iteration = 0\n",
        "    for ep in range(epoch):\n",
        "        # if ep%5 == 0:\n",
        "        scheduler.step()\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            # print(data.shape)\n",
        "            output = model(data).squeeze(0)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            if iteration % log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} Lr: {}'.format(\n",
        "                    ep, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item(), optimizer.param_groups[0]['lr']))\n",
        "            if iteration % save_interval == 0 and iteration > 0:\n",
        "                validate(model)\n",
        "                save_checkpoint('/content/checkpoint/model%i.pth' % iteration, model, optimizer)\n",
        "            iteration += 1\n",
        "        # validate(model)\n",
        "    save_checkpoint('/content/checkpoint/model%i.pth' % iteration, model, optimizer)\n",
        "\n",
        "def validate(model):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(valid_loader.dataset),\n",
        "        100. * correct / len(valid_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrsHQB3bsded"
      },
      "source": [
        "! mkdir -p /content/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWVXbSYpzlMm",
        "outputId": "289a11d3-3fc1-4496-c5d2-f4257b38d90a"
      },
      "source": [
        "train_save(model, 20, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/3680 (0%)]\tLoss: 3.848935 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [400/3680 (11%)]\tLoss: 2.893202 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [800/3680 (22%)]\tLoss: 2.800904 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [1200/3680 (33%)]\tLoss: 1.731881 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [1600/3680 (43%)]\tLoss: 1.826052 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [2000/3680 (54%)]\tLoss: 1.530308 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [2400/3680 (65%)]\tLoss: 1.078519 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [2800/3680 (76%)]\tLoss: 1.022464 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [3200/3680 (87%)]\tLoss: 1.146754 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 0 [3600/3680 (98%)]\tLoss: 0.302758 Lr: 5.9999999999999995e-05\n",
            "Train Epoch: 1 [320/3680 (9%)]\tLoss: 0.863338 Lr: 0.00011999999999999999\n",
            "\n",
            "Test set: Average loss: 0.1346, Accuracy: 1319/1500 (88%)\n",
            "\n",
            "model saved to /content/checkpoint/model1000.pth\n",
            "Train Epoch: 1 [720/3680 (20%)]\tLoss: 0.350667 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [1120/3680 (30%)]\tLoss: 0.877923 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [1520/3680 (41%)]\tLoss: 0.308153 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [1920/3680 (52%)]\tLoss: 0.149574 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [2320/3680 (63%)]\tLoss: 1.374649 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [2720/3680 (74%)]\tLoss: 0.246539 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [3120/3680 (85%)]\tLoss: 0.537173 Lr: 0.00011999999999999999\n",
            "Train Epoch: 1 [3520/3680 (96%)]\tLoss: 0.380379 Lr: 0.00011999999999999999\n",
            "Train Epoch: 2 [240/3680 (7%)]\tLoss: 0.519366 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [640/3680 (17%)]\tLoss: 0.637071 Lr: 0.00017999999999999998\n",
            "\n",
            "Test set: Average loss: 0.0675, Accuracy: 1395/1500 (93%)\n",
            "\n",
            "model saved to /content/checkpoint/model2000.pth\n",
            "Train Epoch: 2 [1040/3680 (28%)]\tLoss: 0.053735 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [1440/3680 (39%)]\tLoss: 0.559151 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [1840/3680 (50%)]\tLoss: 0.169158 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [2240/3680 (61%)]\tLoss: 0.230048 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [2640/3680 (72%)]\tLoss: 0.057372 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [3040/3680 (83%)]\tLoss: 0.136298 Lr: 0.00017999999999999998\n",
            "Train Epoch: 2 [3440/3680 (93%)]\tLoss: 0.887804 Lr: 0.00017999999999999998\n",
            "Train Epoch: 3 [160/3680 (4%)]\tLoss: 0.287379 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [560/3680 (15%)]\tLoss: 0.359688 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [960/3680 (26%)]\tLoss: 0.515370 Lr: 0.00023999999999999998\n",
            "\n",
            "Test set: Average loss: 0.0562, Accuracy: 1385/1500 (92%)\n",
            "\n",
            "model saved to /content/checkpoint/model3000.pth\n",
            "Train Epoch: 3 [1360/3680 (37%)]\tLoss: 0.188638 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [1760/3680 (48%)]\tLoss: 0.022042 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [2160/3680 (59%)]\tLoss: 0.093432 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [2560/3680 (70%)]\tLoss: 0.712345 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [2960/3680 (80%)]\tLoss: 0.200492 Lr: 0.00023999999999999998\n",
            "Train Epoch: 3 [3360/3680 (91%)]\tLoss: 0.615176 Lr: 0.00023999999999999998\n",
            "Train Epoch: 4 [80/3680 (2%)]\tLoss: 0.081144 Lr: 0.0003\n",
            "Train Epoch: 4 [480/3680 (13%)]\tLoss: 0.293081 Lr: 0.0003\n",
            "Train Epoch: 4 [880/3680 (24%)]\tLoss: 0.013256 Lr: 0.0003\n",
            "Train Epoch: 4 [1280/3680 (35%)]\tLoss: 0.138745 Lr: 0.0003\n",
            "\n",
            "Test set: Average loss: 0.0530, Accuracy: 1407/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model4000.pth\n",
            "Train Epoch: 4 [1680/3680 (46%)]\tLoss: 0.012262 Lr: 0.0003\n",
            "Train Epoch: 4 [2080/3680 (57%)]\tLoss: 0.009120 Lr: 0.0003\n",
            "Train Epoch: 4 [2480/3680 (67%)]\tLoss: 0.332361 Lr: 0.0003\n",
            "Train Epoch: 4 [2880/3680 (78%)]\tLoss: 0.268714 Lr: 0.0003\n",
            "Train Epoch: 4 [3280/3680 (89%)]\tLoss: 0.034888 Lr: 0.0003\n",
            "Train Epoch: 5 [0/3680 (0%)]\tLoss: 0.851303 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [400/3680 (11%)]\tLoss: 0.314878 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [800/3680 (22%)]\tLoss: 0.139672 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [1200/3680 (33%)]\tLoss: 0.020289 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [1600/3680 (43%)]\tLoss: 0.043340 Lr: 0.0002967221401100708\n",
            "\n",
            "Test set: Average loss: 0.0529, Accuracy: 1395/1500 (93%)\n",
            "\n",
            "model saved to /content/checkpoint/model5000.pth\n",
            "Train Epoch: 5 [2000/3680 (54%)]\tLoss: 0.318423 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [2400/3680 (65%)]\tLoss: 0.132825 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [2800/3680 (76%)]\tLoss: 0.242062 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [3200/3680 (87%)]\tLoss: 0.012657 Lr: 0.0002967221401100708\n",
            "Train Epoch: 5 [3600/3680 (98%)]\tLoss: 0.027733 Lr: 0.0002967221401100708\n",
            "Train Epoch: 6 [320/3680 (9%)]\tLoss: 0.167700 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [720/3680 (20%)]\tLoss: 0.792340 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [1120/3680 (30%)]\tLoss: 0.376382 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [1520/3680 (41%)]\tLoss: 0.660079 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [1920/3680 (52%)]\tLoss: 0.032306 Lr: 0.0002870318186463901\n",
            "\n",
            "Test set: Average loss: 0.0573, Accuracy: 1393/1500 (93%)\n",
            "\n",
            "model saved to /content/checkpoint/model6000.pth\n",
            "Train Epoch: 6 [2320/3680 (63%)]\tLoss: 0.139822 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [2720/3680 (74%)]\tLoss: 0.011330 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [3120/3680 (85%)]\tLoss: 0.032422 Lr: 0.0002870318186463901\n",
            "Train Epoch: 6 [3520/3680 (96%)]\tLoss: 0.118039 Lr: 0.0002870318186463901\n",
            "Train Epoch: 7 [240/3680 (7%)]\tLoss: 0.016262 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [640/3680 (17%)]\tLoss: 0.370171 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [1040/3680 (28%)]\tLoss: 0.016464 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [1440/3680 (39%)]\tLoss: 0.069018 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [1840/3680 (50%)]\tLoss: 0.313965 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [2240/3680 (61%)]\tLoss: 0.202381 Lr: 0.0002713525491562421\n",
            "\n",
            "Test set: Average loss: 0.0577, Accuracy: 1399/1500 (93%)\n",
            "\n",
            "model saved to /content/checkpoint/model7000.pth\n",
            "Train Epoch: 7 [2640/3680 (72%)]\tLoss: 0.006012 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [3040/3680 (83%)]\tLoss: 0.275908 Lr: 0.0002713525491562421\n",
            "Train Epoch: 7 [3440/3680 (93%)]\tLoss: 0.201087 Lr: 0.0002713525491562421\n",
            "Train Epoch: 8 [160/3680 (4%)]\tLoss: 0.012822 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [560/3680 (15%)]\tLoss: 0.078406 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [960/3680 (26%)]\tLoss: 0.863796 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [1360/3680 (37%)]\tLoss: 0.053869 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [1760/3680 (48%)]\tLoss: 0.296247 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [2160/3680 (59%)]\tLoss: 0.011854 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [2560/3680 (70%)]\tLoss: 0.507578 Lr: 0.0002503695909538287\n",
            "\n",
            "Test set: Average loss: 0.0530, Accuracy: 1403/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model8000.pth\n",
            "Train Epoch: 8 [2960/3680 (80%)]\tLoss: 0.043399 Lr: 0.0002503695909538287\n",
            "Train Epoch: 8 [3360/3680 (91%)]\tLoss: 0.098313 Lr: 0.0002503695909538287\n",
            "Train Epoch: 9 [80/3680 (2%)]\tLoss: 0.013587 Lr: 0.000225\n",
            "Train Epoch: 9 [480/3680 (13%)]\tLoss: 0.143247 Lr: 0.000225\n",
            "Train Epoch: 9 [880/3680 (24%)]\tLoss: 0.001722 Lr: 0.000225\n",
            "Train Epoch: 9 [1280/3680 (35%)]\tLoss: 0.007844 Lr: 0.000225\n",
            "Train Epoch: 9 [1680/3680 (46%)]\tLoss: 0.035869 Lr: 0.000225\n",
            "Train Epoch: 9 [2080/3680 (57%)]\tLoss: 0.013747 Lr: 0.000225\n",
            "Train Epoch: 9 [2480/3680 (67%)]\tLoss: 0.002355 Lr: 0.000225\n",
            "Train Epoch: 9 [2880/3680 (78%)]\tLoss: 0.029169 Lr: 0.000225\n",
            "\n",
            "Test set: Average loss: 0.0573, Accuracy: 1405/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model9000.pth\n",
            "Train Epoch: 9 [3280/3680 (89%)]\tLoss: 0.001326 Lr: 0.000225\n",
            "Train Epoch: 10 [0/3680 (0%)]\tLoss: 0.007210 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [400/3680 (11%)]\tLoss: 0.039413 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [800/3680 (22%)]\tLoss: 0.065187 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [1200/3680 (33%)]\tLoss: 0.007693 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [1600/3680 (43%)]\tLoss: 0.406635 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [2000/3680 (54%)]\tLoss: 0.016281 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [2400/3680 (65%)]\tLoss: 0.011631 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [2800/3680 (76%)]\tLoss: 0.001327 Lr: 0.0001963525491562421\n",
            "Train Epoch: 10 [3200/3680 (87%)]\tLoss: 0.092977 Lr: 0.0001963525491562421\n",
            "\n",
            "Test set: Average loss: 0.0603, Accuracy: 1403/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model10000.pth\n",
            "Train Epoch: 10 [3600/3680 (98%)]\tLoss: 0.001272 Lr: 0.0001963525491562421\n",
            "Train Epoch: 11 [320/3680 (9%)]\tLoss: 0.161477 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [720/3680 (20%)]\tLoss: 0.021488 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [1120/3680 (30%)]\tLoss: 0.027489 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [1520/3680 (41%)]\tLoss: 0.005034 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [1920/3680 (52%)]\tLoss: 0.004989 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [2320/3680 (63%)]\tLoss: 0.004844 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [2720/3680 (74%)]\tLoss: 0.908380 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [3120/3680 (85%)]\tLoss: 0.003077 Lr: 0.000165679269490148\n",
            "Train Epoch: 11 [3520/3680 (96%)]\tLoss: 0.002032 Lr: 0.000165679269490148\n",
            "\n",
            "Test set: Average loss: 0.0609, Accuracy: 1408/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model11000.pth\n",
            "Train Epoch: 12 [240/3680 (7%)]\tLoss: 0.009374 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [640/3680 (17%)]\tLoss: 0.081456 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [1040/3680 (28%)]\tLoss: 0.021827 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [1440/3680 (39%)]\tLoss: 0.009218 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [1840/3680 (50%)]\tLoss: 0.005594 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [2240/3680 (61%)]\tLoss: 0.133740 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [2640/3680 (72%)]\tLoss: 0.004855 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [3040/3680 (83%)]\tLoss: 0.012459 Lr: 0.000134320730509852\n",
            "Train Epoch: 12 [3440/3680 (93%)]\tLoss: 0.004774 Lr: 0.000134320730509852\n",
            "Train Epoch: 13 [160/3680 (4%)]\tLoss: 0.073357 Lr: 0.0001036474508437579\n",
            "\n",
            "Test set: Average loss: 0.0584, Accuracy: 1413/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model12000.pth\n",
            "Train Epoch: 13 [560/3680 (15%)]\tLoss: 0.000431 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [960/3680 (26%)]\tLoss: 0.070711 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [1360/3680 (37%)]\tLoss: 0.011135 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [1760/3680 (48%)]\tLoss: 0.060458 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [2160/3680 (59%)]\tLoss: 0.013193 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [2560/3680 (70%)]\tLoss: 0.036433 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [2960/3680 (80%)]\tLoss: 0.000900 Lr: 0.0001036474508437579\n",
            "Train Epoch: 13 [3360/3680 (91%)]\tLoss: 0.050423 Lr: 0.0001036474508437579\n",
            "Train Epoch: 14 [80/3680 (2%)]\tLoss: 0.003861 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [480/3680 (13%)]\tLoss: 0.007290 Lr: 7.500000000000002e-05\n",
            "\n",
            "Test set: Average loss: 0.0578, Accuracy: 1414/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model13000.pth\n",
            "Train Epoch: 14 [880/3680 (24%)]\tLoss: 0.364208 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [1280/3680 (35%)]\tLoss: 0.005298 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [1680/3680 (46%)]\tLoss: 0.084948 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [2080/3680 (57%)]\tLoss: 0.003766 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [2480/3680 (67%)]\tLoss: 0.002280 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [2880/3680 (78%)]\tLoss: 0.008246 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 14 [3280/3680 (89%)]\tLoss: 0.064374 Lr: 7.500000000000002e-05\n",
            "Train Epoch: 15 [0/3680 (0%)]\tLoss: 0.018283 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [400/3680 (11%)]\tLoss: 0.003609 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [800/3680 (22%)]\tLoss: 0.011807 Lr: 4.963040904617131e-05\n",
            "\n",
            "Test set: Average loss: 0.0541, Accuracy: 1412/1500 (94%)\n",
            "\n",
            "model saved to /content/checkpoint/model14000.pth\n",
            "Train Epoch: 15 [1200/3680 (33%)]\tLoss: 0.007412 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [1600/3680 (43%)]\tLoss: 0.048678 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [2000/3680 (54%)]\tLoss: 0.002090 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [2400/3680 (65%)]\tLoss: 0.009629 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [2800/3680 (76%)]\tLoss: 0.002559 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [3200/3680 (87%)]\tLoss: 0.021396 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 15 [3600/3680 (98%)]\tLoss: 0.003976 Lr: 4.963040904617131e-05\n",
            "Train Epoch: 16 [320/3680 (9%)]\tLoss: 0.012948 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [720/3680 (20%)]\tLoss: 0.105650 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [1120/3680 (30%)]\tLoss: 0.133141 Lr: 2.8647450843757897e-05\n",
            "\n",
            "Test set: Average loss: 0.0555, Accuracy: 1419/1500 (95%)\n",
            "\n",
            "model saved to /content/checkpoint/model15000.pth\n",
            "Train Epoch: 16 [1520/3680 (41%)]\tLoss: 0.001031 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [1920/3680 (52%)]\tLoss: 0.006922 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [2320/3680 (63%)]\tLoss: 0.001344 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [2720/3680 (74%)]\tLoss: 0.003699 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [3120/3680 (85%)]\tLoss: 0.001845 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 16 [3520/3680 (96%)]\tLoss: 0.004932 Lr: 2.8647450843757897e-05\n",
            "Train Epoch: 17 [240/3680 (7%)]\tLoss: 0.002040 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [640/3680 (17%)]\tLoss: 0.206999 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [1040/3680 (28%)]\tLoss: 0.001830 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [1440/3680 (39%)]\tLoss: 0.008341 Lr: 1.2968181353609852e-05\n",
            "\n",
            "Test set: Average loss: 0.0551, Accuracy: 1420/1500 (95%)\n",
            "\n",
            "model saved to /content/checkpoint/model16000.pth\n",
            "Train Epoch: 17 [1840/3680 (50%)]\tLoss: 0.007827 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [2240/3680 (61%)]\tLoss: 0.000438 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [2640/3680 (72%)]\tLoss: 0.026875 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [3040/3680 (83%)]\tLoss: 0.000737 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 17 [3440/3680 (93%)]\tLoss: 0.006233 Lr: 1.2968181353609852e-05\n",
            "Train Epoch: 18 [160/3680 (4%)]\tLoss: 0.004078 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [560/3680 (15%)]\tLoss: 0.007584 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [960/3680 (26%)]\tLoss: 0.093719 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [1360/3680 (37%)]\tLoss: 0.003599 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [1760/3680 (48%)]\tLoss: 0.027884 Lr: 3.2778598899291465e-06\n",
            "\n",
            "Test set: Average loss: 0.0551, Accuracy: 1421/1500 (95%)\n",
            "\n",
            "model saved to /content/checkpoint/model17000.pth\n",
            "Train Epoch: 18 [2160/3680 (59%)]\tLoss: 0.001117 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [2560/3680 (70%)]\tLoss: 0.025949 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [2960/3680 (80%)]\tLoss: 0.006781 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 18 [3360/3680 (91%)]\tLoss: 0.009370 Lr: 3.2778598899291465e-06\n",
            "Train Epoch: 19 [80/3680 (2%)]\tLoss: 0.268962 Lr: 0.0\n",
            "Train Epoch: 19 [480/3680 (13%)]\tLoss: 0.018348 Lr: 0.0\n",
            "Train Epoch: 19 [880/3680 (24%)]\tLoss: 0.340361 Lr: 0.0\n",
            "Train Epoch: 19 [1280/3680 (35%)]\tLoss: 0.002262 Lr: 0.0\n",
            "Train Epoch: 19 [1680/3680 (46%)]\tLoss: 0.006233 Lr: 0.0\n",
            "Train Epoch: 19 [2080/3680 (57%)]\tLoss: 0.003561 Lr: 0.0\n",
            "\n",
            "Test set: Average loss: 0.0551, Accuracy: 1421/1500 (95%)\n",
            "\n",
            "model saved to /content/checkpoint/model18000.pth\n",
            "Train Epoch: 19 [2480/3680 (67%)]\tLoss: 0.000823 Lr: 0.0\n",
            "Train Epoch: 19 [2880/3680 (78%)]\tLoss: 0.026884 Lr: 0.0\n",
            "Train Epoch: 19 [3280/3680 (89%)]\tLoss: 0.015606 Lr: 0.0\n",
            "model saved to /content/checkpoint/model18400.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCz1ITZeTUsK"
      },
      "source": [
        "! cp -r /content/checkpoint/model18400.pth /content/drive/MyDrive/DLCV/HW3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUpGIv9rpsEr"
      },
      "source": [
        "# **Validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N_cer5jswTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25ed3a81-f55c-4449-c413-191c42b12377"
      },
      "source": [
        "state = torch.load('/content/checkpoint/model18400.pth')\n",
        "model.load_state_dict(state['state_dict'])\n",
        "# optimizer.load_state_dict(state['optimizer'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFXL_6JjpzC6"
      },
      "source": [
        "def validate(model, result):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in valid_loader:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            for k in pred:\n",
        "              result.append(int(k.cpu()))\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(valid_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(valid_loader.dataset),\n",
        "        100. * correct / len(valid_loader.dataset)))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N0OAYdQimz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7256f1f3-28ca-4d50-d964-14d8ba0f5142"
      },
      "source": [
        "Y = []\n",
        "Y = validate(model,Y)\n",
        "print(len(Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0551, Accuracy: 1421/1500 (95%)\n",
            "\n",
            "1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1X3lXviNXyF"
      },
      "source": [
        "# ! mkdir -p \n",
        "! cp -r /content/checkpoint/model13000.pth /content/drive/MyDrive/DLCV/HW3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5kt6vFsD4ka"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/data/val_gt.csv', newline='') as csvfile:\n",
        "\n",
        "    # 讀取 CSV 檔案內容\n",
        "    rows = csv.reader(csvfile)\n",
        "    Rows = list(rows)\n",
        "    data_names = []\n",
        "    for i in range(1,len(Rows)):\n",
        "      data_names.append(Rows[i][0])\n",
        "    # print(datas)\n",
        "\n",
        "with open('output.csv', 'w') as f:\n",
        "    f.write('image_id,label\\n')\n",
        "    for i, ele in enumerate(Y):\n",
        "        f.write('{},{}\\n'.format(data_names[i],Y[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNcHWzutE97_"
      },
      "source": [
        "!cp -r /content/checkpoint_2/ /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}