{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kai_few_shot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjkNcetLwHdO",
        "outputId": "9356e7e5-056e-47b4-c2fe-8541623538a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  1 16:24:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1YuzCW6s56tV409JRXaAMKFdIkK9xIACw --output \"data.zip\"\n",
        "!unzip -q \"data.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJIqb1xmwOQW",
        "outputId": "c60ffde2-23da-4b21-9423-918d37d447fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YuzCW6s56tV409JRXaAMKFdIkK9xIACw\n",
            "To: /content/data.zip\n",
            "100% 1.13G/1.13G [00:05<00:00, 217MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mVO25XtYwPbm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572828d6-1aef-40d8-a279-c611741e0406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)\n",
        "\n",
        "# mini-Imagenet dataset\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)"
      ],
      "metadata": {
        "id": "IR6muT_DZqe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "\n",
        "class Convnet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(in_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    bn = nn.BatchNorm2d(out_channels)\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        bn,\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "class Protonet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.conv = Convnet(in_channels, hid_channels, out_channels)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(1600, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 400)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.mlp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "KPeAN8MLZykC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Sampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class NShotTaskSampler(Sampler):\n",
        "    def __init__(self, csv_path, episodes_per_epoch, N_way, N_shot, N_query):\n",
        "        self.data_df = pd.read_csv(csv_path)\n",
        "        self.N_way = N_way\n",
        "        self.N_shot = N_shot\n",
        "        self.N_query = N_query\n",
        "        self.episodes_per_epoch = episodes_per_epoch\n",
        "\n",
        "    def __iter__(self):\n",
        "        for _ in range(self.episodes_per_epoch):\n",
        "            batch = []\n",
        "            episode_classes = np.random.choice(self.data_df['label'].unique(), size=self.N_way, replace=False)\n",
        "\n",
        "            support = []\n",
        "            query = []\n",
        "\n",
        "            for k in episode_classes:\n",
        "                ind = self.data_df[self.data_df['label'] == k]['id'].sample(self.N_shot + self.N_query).values\n",
        "                support = support + list(ind[:self.N_shot])\n",
        "                query = query + list(ind[self.N_shot:])\n",
        "\n",
        "            batch = support + query\n",
        "\n",
        "            yield np.stack(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.episodes_per_epoch\n",
        "\n",
        "\n",
        "class GeneratorSampler(Sampler):\n",
        "    def __init__(self, episode_file_path):\n",
        "        episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\n",
        "        self.sampled_sequence = episode_df.values.flatten().tolist()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.sampled_sequence) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sampled_sequence)"
      ],
      "metadata": {
        "id": "neMxFoEBZ2jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def pairwise_distances(x, y, matching_fn='l2', parametric=None):\n",
        "    n_x = x.shape[0]\n",
        "    n_y = y.shape[0]\n",
        "\n",
        "    if matching_fn == 'l2':\n",
        "        distances = (\n",
        "                x.unsqueeze(1).expand(n_x, n_y, -1) -\n",
        "                y.unsqueeze(0).expand(n_x, n_y, -1)\n",
        "        ).pow(2).sum(dim=2)\n",
        "        return distances\n",
        "    elif matching_fn == 'cosine':\n",
        "        cos = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
        "        cosine_similarities = cos(x.unsqueeze(1).expand(n_x, n_y, -1), y.unsqueeze(0).expand(n_x, n_y, -1))\n",
        "\n",
        "        return 1 - cosine_similarities\n",
        "    elif matching_fn == 'parametric':\n",
        "        x_exp = x.unsqueeze(1).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "        y_exp = y.unsqueeze(0).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "        \n",
        "        distances = parametric(torch.cat([x_exp, y_exp], dim=-1))\n",
        "        \n",
        "        return distances.reshape(n_x, n_y)\n",
        "\n",
        "    else:\n",
        "        raise(ValueError('Unsupported similarity function'))"
      ],
      "metadata": {
        "id": "n1rIF632Z7lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "# from model import Protonet\n",
        "# from utils import pairwise_distances\n",
        "\n",
        "\n",
        "class Solver(object):\n",
        "    def __init__(self, config, train_loader, val_loader):\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        self.device = torch.device('cuda' if self.use_cuda else 'cpu')\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.N_way_train = config.N_way_train\n",
        "        self.N_shot_train = config.N_shot_train\n",
        "        self.N_query_train = config.N_query_train\n",
        "        self.N_way_val = config.N_way_val\n",
        "        self.N_shot_val = config.N_shot_val\n",
        "        self.N_query_val = config.N_query_val\n",
        "        self.matching_fn = config.matching_fn\n",
        "\n",
        "        self.num_epochs = config.num_epochs\n",
        "        self.resume_iter = config.resume_iter\n",
        "        self.lr = config.lr\n",
        "        self.num_steps_decay = config.num_steps_decay\n",
        "        self.beta1 = config.beta1\n",
        "        self.beta2 = config.beta2\n",
        "        self.weight_decay = config.weight_decay\n",
        "        self.exp_name = config.name\n",
        "        os.makedirs(config.ckp_dir, exist_ok=True)\n",
        "        self.ckp_dir = os.path.join(config.ckp_dir, self.exp_name)\n",
        "        os.makedirs(self.ckp_dir, exist_ok=True)\n",
        "        self.log_interval = config.log_interval\n",
        "        self.ckp_interval = config.ckp_interval\n",
        "\n",
        "        self.use_wandb = config.use_wandb\n",
        "        \n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        self.model = Protonet().to(self.device)\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr,  betas=[self.beta1, self.beta2], weight_decay=self.weight_decay)\n",
        "        if self.matching_fn == 'parametric':\n",
        "            self.parametric = nn.Sequential(\n",
        "                nn.Linear(800, 400),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(400, 1)\n",
        "            ).to(self.device)\n",
        "            self.optimizer = torch.optim.AdamW(list(self.model.parameters()) + list(self.parametric.parameters()), lr=self.lr,  betas=[self.beta1, self.beta2], weight_decay=self.weight_decay)\n",
        "        self.scheduler = StepLR(self.optimizer, step_size=self.num_steps_decay, gamma=0.9)\n",
        "\n",
        "    def save_checkpoint(self, step):\n",
        "        state = {'state_dict': self.model.state_dict(),\n",
        "                 'optimizer' : self.optimizer.state_dict()}\n",
        "        if self.matching_fn == 'parametric':\n",
        "            state = {'state_dict': self.model.state_dict(),\n",
        "                     'optimizer' : self.optimizer.state_dict(),\n",
        "                     'parametric': self.parametric.state_dict()}\n",
        "\n",
        "        new_checkpoint_path = os.path.join(self.ckp_dir, '{}-protonet.pth'.format(step + 1))\n",
        "        torch.save(state, new_checkpoint_path)\n",
        "        print('model saved to %s' % new_checkpoint_path)\n",
        "\n",
        "    def load_checkpoint(self, resume_iter):\n",
        "        print('Loading the trained models from step {}...'.format(resume_iter))\n",
        "        new_checkpoint_path = os.path.join(self.ckp_dir, '{}-protonet.pth'.format(resume_iter))\n",
        "        state = torch.load(new_checkpoint_path)\n",
        "        self.model.load_state_dict(state['state_dict'])\n",
        "        self.optimizer.load_state_dict(state['optimizer'])\n",
        "        if self.matching_fn == 'parametric':\n",
        "            self.parametric.load_state_dict(state['parametric'])\n",
        "        print('model loaded from %s' % new_checkpoint_path)\n",
        "    \n",
        "    def train(self):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        best_mean = 0\n",
        "        iteration = 0\n",
        "\n",
        "        if self.resume_iter:\n",
        "            print(\"resuming step %d ...\"% self.resume_iter)\n",
        "            iteration = self.resume_iter\n",
        "            self.load_checkpoint(self.resume_iter)\n",
        "            loss, mean, std = self.eval()\n",
        "            if mean > best_mean:\n",
        "                best_mean = mean\n",
        "\n",
        "        episodic_acc = []\n",
        "\n",
        "        for ep in range(self.num_epochs):\n",
        "            self.model.train()\n",
        "\n",
        "            for batch_idx, (data, target) in enumerate(self.train_loader):\n",
        "                data = data.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                support_input = data[:self.N_way_train * self.N_shot_train,:,:,:] \n",
        "                query_input   = data[self.N_way_train * self.N_shot_train:,:,:,:]\n",
        "\n",
        "                label_encoder = {target[i * self.N_shot_train] : i for i in range(self.N_way_train)}\n",
        "                query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[self.N_way_train * self.N_shot_train:]])\n",
        "\n",
        "                support = self.model(support_input)\n",
        "                queries = self.model(query_input)\n",
        "                prototypes = support.reshape(self.N_way_train, self.N_shot_train, -1).mean(dim=1)\n",
        "\n",
        "                if self.matching_fn == 'parametric':\n",
        "                    distances = pairwise_distances(queries, prototypes, self.matching_fn, self.parametric)\n",
        "\n",
        "                else:\n",
        "                    distances = pairwise_distances(queries, prototypes, self.matching_fn)\n",
        "\n",
        "                loss = criterion(-distances, query_label)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                y_pred = (-distances).softmax(dim=1).max(1, keepdim=True)[1]\n",
        "                episodic_acc.append(1. * y_pred.eq(query_label.view_as(y_pred)).sum().item() / len(query_label))\n",
        "\n",
        "\n",
        "                if (iteration + 1) % self.log_interval == 0:\n",
        "                    episodic_acc = np.array(episodic_acc)\n",
        "                    mean = episodic_acc.mean()\n",
        "                    std = episodic_acc.std()\n",
        "\n",
        "                    print('Epoch: {:3d} [{:d}/{:d}]\\tIteration: {:5d}\\tLoss: {:.6f}\\tAccuracy: {:.2f} +- {:.2f} %'.format(\n",
        "                        ep, (batch_idx + 1), len(self.train_loader), iteration + 1, loss.item(), \n",
        "                        mean * 100, 1.96 * std / (self.log_interval)**(1/2) * 100))\n",
        "\n",
        "                    if self.use_wandb:\n",
        "                        import wandb\n",
        "                        wandb.log({\"loss\": loss.item(),\n",
        "                                   \"acc_mean\": mean * 100,\n",
        "                                   \"acc_ci\": 1.96 * std / (self.log_interval)**(1/2) * 100,\n",
        "                                   'lr': self.optimizer.param_groups[0]['lr']\n",
        "                                   }, \n",
        "                                   step=iteration+1)\n",
        "\n",
        "                    episodic_acc = []\n",
        "\n",
        "\n",
        "                if (iteration + 1) % self.ckp_interval == 0:\n",
        "                    loss, mean, std = self.eval()\n",
        "                    if mean > best_mean:\n",
        "                        best_mean = mean\n",
        "                        self.save_checkpoint(iteration)\n",
        "                        if self.use_wandb:\n",
        "                            wandb.run.summary[\"best_accuracy\"] = best_mean * 100\n",
        "\n",
        "                    if self.use_wandb:\n",
        "                        import wandb\n",
        "                        wandb.log({\"val_loss\": loss,\n",
        "                                   \"val_acc_mean\": mean * 100,\n",
        "                                   \"val_acc_ci\": 1.96 * std / (600)**(1/2) * 100}, \n",
        "                                   step=iteration+1, commit=False)\n",
        "\n",
        "                iteration += 1\n",
        "\n",
        "            self.scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def eval(self):\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        self.model.eval()\n",
        "        episodic_acc = []\n",
        "        loss = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for b_idx, (data, target) in enumerate(self.val_loader):\n",
        "                data = data.to(self.device)\n",
        "                support_input = data[:self.N_way_val * self.N_shot_val,:,:,:] \n",
        "                query_input = data[self.N_way_val * self.N_shot_val:,:,:,:]\n",
        "\n",
        "                label_encoder = {target[i * self.N_shot_val] : i for i in range(self.N_way_val)}\n",
        "                query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[self.N_way_val * self.N_shot_val:]])\n",
        "\n",
        "                support = self.model(support_input)\n",
        "                queries = self.model(query_input)\n",
        "                prototypes = support.reshape(self.N_way_val, self.N_shot_val, -1).mean(dim=1)\n",
        "\n",
        "                if self.matching_fn == 'parametric':\n",
        "                    distances = pairwise_distances(queries, prototypes, self.matching_fn, self.parametric)\n",
        "                else:\n",
        "                    distances = pairwise_distances(queries, prototypes, self.matching_fn)\n",
        "                    \n",
        "                loss.append(criterion(-distances, query_label).item())\n",
        "                y_pred = (-distances).softmax(dim=1).max(1, keepdim=True)[1]\n",
        "                episodic_acc.append(1. * y_pred.eq(query_label.view_as(y_pred)).sum().item() / len(query_label))\n",
        "\n",
        "        loss = np.array(loss)\n",
        "        episodic_acc = np.array(episodic_acc)\n",
        "        loss = loss.mean()\n",
        "        mean = episodic_acc.mean()\n",
        "        std = episodic_acc.std()\n",
        "\n",
        "        print('\\nLoss: {:.6f}\\tAccuracy: {:.2f} +- {:.2f} %\\n'.format(loss,mean * 100, 1.96 * std / (600)**(1/2) * 100))\n",
        "\n",
        "        return loss, mean, std"
      ],
      "metadata": {
        "id": "5Luw9iAIaFRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from argparse import Namespace\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)\n",
        "\n",
        "# from dataset import MiniDataset\n",
        "# from samplers import GeneratorSampler, NShotTaskSampler\n",
        "# from solver import Solver\n",
        "\n",
        "# fix random seeds for reproducibility\n",
        "SEED = 123\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def worker_init_fn(worker_id):                                                          \n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "\n",
        "def parse_args():\n",
        "    # parser = argparse.ArgumentParser(description=\"Few shot learning\")\n",
        "\n",
        "    # # training configuration.\n",
        "    # parser.add_argument('--episodes_per_epoch', default=600, type=int, help='episodes per epoch')\n",
        "    # parser.add_argument('--N_way_train', default=5, type=int, help='N_way (default: 5) for training')\n",
        "    # parser.add_argument('--N_shot_train', default=1, type=int, help='N_shot (default: 1) for training')\n",
        "    # parser.add_argument('--N_query_train', default=15, type=int, help='N_query (default: 15) for training')\n",
        "    # parser.add_argument('--N_way_val', default=5, type=int, help='N_way (default: 5) for val')\n",
        "    # parser.add_argument('--N_shot_val', default=1, type=int, help='N_shot (default: 1) for val')\n",
        "    # parser.add_argument('--N_query_val', default=15, type=int, help='N_query (default: 15) for val')\n",
        "    # parser.add_argument('--matching_fn', default='l2', type=str, choices=['l2', 'cosine', 'parametric'], help='distance matching function')\n",
        "\n",
        "    # # optimizer configuration\n",
        "    # parser.add_argument(\"--lr\", help=\"the learning rate\", default=1e-4, type=float)\n",
        "    # parser.add_argument('--num_steps_decay', type=int, default=40, help='number of steps for decaying lr')\n",
        "    # parser.add_argument('--beta1', type=float, default=0.9, help='beta1 for Adam optimizer')\n",
        "    # parser.add_argument('--beta2', type=float, default=0.999, help='beta2 for Adam optimizer')\n",
        "    # parser.add_argument('--weight_decay', type=float, default=1e-2, help='weight_decay for Adam optimizer')\n",
        "\n",
        "    # # path.\n",
        "    # parser.add_argument('--train_csv', type=str, default='../hw4_data/train.csv', help=\"Training images csv file\")\n",
        "    # parser.add_argument('--train_data_dir', type=str, default='../hw4_data/train', help=\"Training images directory\")\n",
        "    # parser.add_argument('--val_csv', type=str, default='../hw4_data/val.csv', help=\"val images csv file\")\n",
        "    # parser.add_argument('--val_data_dir', type=str, default='../hw4_data/val', help=\"val images directory\")\n",
        "    # parser.add_argument('--val_testcase_csv', type=str, default='../hw4_data/val_testcase.csv', help=\"val test case csv\")\n",
        "    # parser.add_argument('--ckp_dir', default='ckpt/', type=str, help='Checkpoint path', required=False)\n",
        "    # parser.add_argument('--name', default='', type=str, help='Name for saving model')\n",
        "\n",
        "    # # Step size.\n",
        "    # parser.add_argument('--num_epochs', type=int, default=100, help='number of total epochs')\n",
        "    # parser.add_argument('--resume_iter', type=int, default=0, help='resume training from this epoch')\n",
        "    # parser.add_argument('--log_interval', type=int, default=300)\n",
        "    # parser.add_argument('--ckp_interval', type=int, default=600)\n",
        "\n",
        "    # # Others\n",
        "    # parser.add_argument(\"--use_wandb\", help=\"log training with wandb, \"\n",
        "    #     \"requires wandb, install with \\\"pip install wandb\\\"\", action=\"store_true\")\n",
        "\n",
        "    # return parser.parse_args()\n",
        "    \n",
        "    parameters = {\n",
        "        'episodes_per_epoch': 100,\n",
        "        'N_way_train': 5,\n",
        "        'N_shot_train': 10,\n",
        "        'N_query_train': 15,\n",
        "        'N_way_val': 5,\n",
        "        'N_shot_val': 1,\n",
        "        'N_query_val': 15,\n",
        "        'matching_fn': 'parametric',\n",
        "\n",
        "        'lr': 1e-4,\n",
        "        'num_steps_decay': 40,\n",
        "        'beta1': 0.9,\n",
        "        'beta2': 0.999,\n",
        "        'weight_decay': 1e-2,\n",
        "\n",
        "        'train_csv': '/content/hw4_data/mini/train.csv',\n",
        "        'train_data_dir': '/content/hw4_data/mini/train',\n",
        "        'val_csv': '/content/hw4_data/mini/val.csv',\n",
        "        'val_data_dir': '/content/hw4_data/mini/val',\n",
        "        'val_testcase_csv': '/content/hw4_data/mini/val_testcase.csv',\n",
        "        'ckp_dir': './ckpt_cos',\n",
        "        'name': '',\n",
        "\n",
        "        'num_epochs': 200,\n",
        "        'resume_iter': 0,\n",
        "        'log_interval': 300,\n",
        "        'ckp_interval': 600,\n",
        "\n",
        "        'use_wandb': False,\n",
        "\n",
        "    }\n",
        "    config = Namespace(**parameters)\n",
        "\n",
        "    return config\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    args = parse_args()\n",
        "\n",
        "    if args.use_wandb:\n",
        "        import wandb\n",
        "        wandb.init(project=\"few-shot-learning\", config=args)\n",
        "        args = wandb.config\n",
        "        print(args)\n",
        "\n",
        "    train_dataset = MiniDataset(args.train_csv, args.train_data_dir)\n",
        "    val_dataset = MiniDataset(args.val_csv, args.val_data_dir)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        num_workers=3, pin_memory=False, worker_init_fn=worker_init_fn,\n",
        "        batch_sampler=NShotTaskSampler(args.train_csv, args.episodes_per_epoch, args.N_way_train, args.N_shot_train, args.N_query_train))\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=args.N_way_val * (args.N_query_val + args.N_shot_val),\n",
        "        num_workers=3, pin_memory=False, worker_init_fn=worker_init_fn,\n",
        "        sampler=GeneratorSampler(args.val_testcase_csv))\n",
        "\n",
        "    solver = Solver(args, train_loader, val_loader)\n",
        "\n",
        "    solver.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cHSuQgQaFzV",
        "outputId": "2ead4036-87bb-4e9e-833d-d2cea99e19f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   2 [100/100]\tIteration:   300\tLoss: 1.413023\tAccuracy: 26.13 +- 0.85 %\n",
            "Epoch:   5 [100/100]\tIteration:   600\tLoss: 1.398427\tAccuracy: 33.86 +- 0.90 %\n",
            "\n",
            "Loss: 1.583953\tAccuracy: 27.23 +- 0.56 %\n",
            "\n",
            "model saved to ./ckpt_cos/600-protonet.pth\n",
            "Epoch:   8 [100/100]\tIteration:   900\tLoss: 1.522658\tAccuracy: 35.12 +- 0.91 %\n",
            "Epoch:  11 [100/100]\tIteration:  1200\tLoss: 1.429200\tAccuracy: 35.57 +- 0.91 %\n",
            "\n",
            "Loss: 1.643131\tAccuracy: 28.56 +- 0.58 %\n",
            "\n",
            "model saved to ./ckpt_cos/1200-protonet.pth\n",
            "Epoch:  14 [100/100]\tIteration:  1500\tLoss: 1.520076\tAccuracy: 37.32 +- 0.85 %\n",
            "Epoch:  17 [100/100]\tIteration:  1800\tLoss: 1.110024\tAccuracy: 38.17 +- 0.85 %\n",
            "\n",
            "Loss: 1.626902\tAccuracy: 28.64 +- 0.58 %\n",
            "\n",
            "model saved to ./ckpt_cos/1800-protonet.pth\n",
            "Epoch:  20 [100/100]\tIteration:  2100\tLoss: 1.287106\tAccuracy: 39.37 +- 0.90 %\n",
            "Epoch:  23 [100/100]\tIteration:  2400\tLoss: 1.416582\tAccuracy: 40.58 +- 0.96 %\n",
            "\n",
            "Loss: 1.635383\tAccuracy: 29.46 +- 0.62 %\n",
            "\n",
            "model saved to ./ckpt_cos/2400-protonet.pth\n",
            "Epoch:  26 [100/100]\tIteration:  2700\tLoss: 1.234401\tAccuracy: 45.20 +- 0.99 %\n",
            "Epoch:  29 [100/100]\tIteration:  3000\tLoss: 0.977729\tAccuracy: 48.52 +- 1.04 %\n",
            "\n",
            "Loss: 1.689452\tAccuracy: 35.34 +- 0.75 %\n",
            "\n",
            "model saved to ./ckpt_cos/3000-protonet.pth\n",
            "Epoch:  32 [100/100]\tIteration:  3300\tLoss: 0.902261\tAccuracy: 50.52 +- 1.16 %\n",
            "Epoch:  35 [100/100]\tIteration:  3600\tLoss: 1.121727\tAccuracy: 51.27 +- 1.09 %\n",
            "\n",
            "Loss: 1.666605\tAccuracy: 36.28 +- 0.74 %\n",
            "\n",
            "model saved to ./ckpt_cos/3600-protonet.pth\n",
            "Epoch:  38 [100/100]\tIteration:  3900\tLoss: 1.458412\tAccuracy: 51.33 +- 1.16 %\n",
            "Epoch:  41 [100/100]\tIteration:  4200\tLoss: 0.908934\tAccuracy: 53.27 +- 1.16 %\n",
            "\n",
            "Loss: 1.581623\tAccuracy: 36.49 +- 0.74 %\n",
            "\n",
            "model saved to ./ckpt_cos/4200-protonet.pth\n",
            "Epoch:  44 [100/100]\tIteration:  4500\tLoss: 1.123252\tAccuracy: 54.59 +- 1.08 %\n",
            "Epoch:  47 [100/100]\tIteration:  4800\tLoss: 1.037895\tAccuracy: 53.73 +- 1.13 %\n",
            "\n",
            "Loss: 1.555494\tAccuracy: 37.64 +- 0.80 %\n",
            "\n",
            "model saved to ./ckpt_cos/4800-protonet.pth\n",
            "Epoch:  50 [100/100]\tIteration:  5100\tLoss: 0.893279\tAccuracy: 55.04 +- 1.08 %\n",
            "Epoch:  53 [100/100]\tIteration:  5400\tLoss: 1.110964\tAccuracy: 56.20 +- 1.11 %\n",
            "\n",
            "Loss: 1.609467\tAccuracy: 38.13 +- 0.81 %\n",
            "\n",
            "model saved to ./ckpt_cos/5400-protonet.pth\n",
            "Epoch:  56 [100/100]\tIteration:  5700\tLoss: 1.248016\tAccuracy: 55.95 +- 1.19 %\n",
            "Epoch:  59 [100/100]\tIteration:  6000\tLoss: 1.272307\tAccuracy: 57.35 +- 1.05 %\n",
            "\n",
            "Loss: 1.566027\tAccuracy: 38.61 +- 0.80 %\n",
            "\n",
            "model saved to ./ckpt_cos/6000-protonet.pth\n",
            "Epoch:  62 [100/100]\tIteration:  6300\tLoss: 0.381722\tAccuracy: 58.38 +- 1.19 %\n",
            "Epoch:  65 [100/100]\tIteration:  6600\tLoss: 0.846897\tAccuracy: 59.10 +- 1.15 %\n",
            "\n",
            "Loss: 1.663331\tAccuracy: 38.88 +- 0.82 %\n",
            "\n",
            "model saved to ./ckpt_cos/6600-protonet.pth\n",
            "Epoch:  68 [100/100]\tIteration:  6900\tLoss: 1.076616\tAccuracy: 60.36 +- 1.09 %\n",
            "Epoch:  71 [100/100]\tIteration:  7200\tLoss: 1.064832\tAccuracy: 61.44 +- 1.04 %\n",
            "\n",
            "Loss: 1.636185\tAccuracy: 39.41 +- 0.82 %\n",
            "\n",
            "model saved to ./ckpt_cos/7200-protonet.pth\n",
            "Epoch:  74 [100/100]\tIteration:  7500\tLoss: 0.776199\tAccuracy: 63.08 +- 1.09 %\n",
            "Epoch:  77 [100/100]\tIteration:  7800\tLoss: 0.985089\tAccuracy: 62.10 +- 1.16 %\n",
            "\n",
            "Loss: 1.695390\tAccuracy: 39.07 +- 0.81 %\n",
            "\n",
            "Epoch:  80 [100/100]\tIteration:  8100\tLoss: 0.814095\tAccuracy: 64.13 +- 1.12 %\n",
            "Epoch:  83 [100/100]\tIteration:  8400\tLoss: 1.357844\tAccuracy: 64.55 +- 1.18 %\n",
            "\n",
            "Loss: 1.727392\tAccuracy: 40.68 +- 0.80 %\n",
            "\n",
            "model saved to ./ckpt_cos/8400-protonet.pth\n",
            "Epoch:  86 [100/100]\tIteration:  8700\tLoss: 0.676435\tAccuracy: 66.20 +- 1.06 %\n",
            "Epoch:  89 [100/100]\tIteration:  9000\tLoss: 1.490521\tAccuracy: 66.06 +- 1.14 %\n",
            "\n",
            "Loss: 1.683061\tAccuracy: 41.35 +- 0.82 %\n",
            "\n",
            "model saved to ./ckpt_cos/9000-protonet.pth\n",
            "Epoch:  92 [100/100]\tIteration:  9300\tLoss: 0.981030\tAccuracy: 67.09 +- 1.13 %\n",
            "Epoch:  95 [100/100]\tIteration:  9600\tLoss: 0.861108\tAccuracy: 67.53 +- 1.05 %\n",
            "\n",
            "Loss: 1.650509\tAccuracy: 41.03 +- 0.80 %\n",
            "\n",
            "Epoch:  98 [100/100]\tIteration:  9900\tLoss: 0.578047\tAccuracy: 69.06 +- 1.13 %\n",
            "Epoch: 101 [100/100]\tIteration: 10200\tLoss: 0.669552\tAccuracy: 67.84 +- 1.20 %\n",
            "\n",
            "Loss: 1.663958\tAccuracy: 41.83 +- 0.84 %\n",
            "\n",
            "model saved to ./ckpt_cos/10200-protonet.pth\n",
            "Epoch: 104 [100/100]\tIteration: 10500\tLoss: 1.045892\tAccuracy: 69.19 +- 1.15 %\n",
            "Epoch: 107 [100/100]\tIteration: 10800\tLoss: 0.594323\tAccuracy: 69.83 +- 1.11 %\n",
            "\n",
            "Loss: 1.715234\tAccuracy: 42.17 +- 0.85 %\n",
            "\n",
            "model saved to ./ckpt_cos/10800-protonet.pth\n",
            "Epoch: 110 [100/100]\tIteration: 11100\tLoss: 0.683451\tAccuracy: 69.27 +- 1.09 %\n",
            "Epoch: 113 [100/100]\tIteration: 11400\tLoss: 0.480188\tAccuracy: 70.17 +- 1.11 %\n",
            "\n",
            "Loss: 1.750262\tAccuracy: 40.84 +- 0.83 %\n",
            "\n",
            "Epoch: 116 [100/100]\tIteration: 11700\tLoss: 0.955727\tAccuracy: 70.58 +- 1.15 %\n",
            "Epoch: 119 [100/100]\tIteration: 12000\tLoss: 0.519621\tAccuracy: 71.09 +- 1.15 %\n",
            "\n",
            "Loss: 1.730604\tAccuracy: 42.81 +- 0.83 %\n",
            "\n",
            "model saved to ./ckpt_cos/12000-protonet.pth\n",
            "Epoch: 122 [100/100]\tIteration: 12300\tLoss: 0.464698\tAccuracy: 72.03 +- 1.04 %\n",
            "Epoch: 125 [100/100]\tIteration: 12600\tLoss: 0.599426\tAccuracy: 71.44 +- 1.03 %\n",
            "\n",
            "Loss: 1.783882\tAccuracy: 41.76 +- 0.83 %\n",
            "\n",
            "Epoch: 128 [100/100]\tIteration: 12900\tLoss: 0.778605\tAccuracy: 71.86 +- 1.14 %\n",
            "Epoch: 131 [100/100]\tIteration: 13200\tLoss: 0.939315\tAccuracy: 72.88 +- 1.10 %\n",
            "\n",
            "Loss: 1.789116\tAccuracy: 42.07 +- 0.85 %\n",
            "\n",
            "Epoch: 134 [100/100]\tIteration: 13500\tLoss: 0.956397\tAccuracy: 71.94 +- 1.07 %\n",
            "Epoch: 137 [100/100]\tIteration: 13800\tLoss: 0.709347\tAccuracy: 72.76 +- 1.16 %\n",
            "\n",
            "Loss: 1.833958\tAccuracy: 41.84 +- 0.83 %\n",
            "\n",
            "Epoch: 140 [100/100]\tIteration: 14100\tLoss: 0.660557\tAccuracy: 72.84 +- 1.09 %\n",
            "Epoch: 143 [100/100]\tIteration: 14400\tLoss: 0.525991\tAccuracy: 74.11 +- 1.12 %\n",
            "\n",
            "Loss: 1.878912\tAccuracy: 41.32 +- 0.83 %\n",
            "\n",
            "Epoch: 146 [100/100]\tIteration: 14700\tLoss: 0.863456\tAccuracy: 74.07 +- 1.12 %\n",
            "Epoch: 149 [100/100]\tIteration: 15000\tLoss: 0.911676\tAccuracy: 74.93 +- 1.11 %\n",
            "\n",
            "Loss: 1.853603\tAccuracy: 42.35 +- 0.84 %\n",
            "\n",
            "Epoch: 152 [100/100]\tIteration: 15300\tLoss: 0.498339\tAccuracy: 73.74 +- 1.11 %\n",
            "Epoch: 155 [100/100]\tIteration: 15600\tLoss: 1.050233\tAccuracy: 74.56 +- 1.07 %\n",
            "\n",
            "Loss: 1.861492\tAccuracy: 42.05 +- 0.83 %\n",
            "\n",
            "Epoch: 158 [100/100]\tIteration: 15900\tLoss: 0.820249\tAccuracy: 74.38 +- 1.11 %\n",
            "Epoch: 161 [100/100]\tIteration: 16200\tLoss: 0.617322\tAccuracy: 75.23 +- 1.12 %\n",
            "\n",
            "Loss: 1.851759\tAccuracy: 41.76 +- 0.86 %\n",
            "\n",
            "Epoch: 164 [100/100]\tIteration: 16500\tLoss: 1.279891\tAccuracy: 74.67 +- 1.13 %\n",
            "Epoch: 167 [100/100]\tIteration: 16800\tLoss: 0.873963\tAccuracy: 75.44 +- 1.06 %\n",
            "\n",
            "Loss: 2.080113\tAccuracy: 41.78 +- 0.82 %\n",
            "\n",
            "Epoch: 170 [100/100]\tIteration: 17100\tLoss: 0.601974\tAccuracy: 76.47 +- 1.08 %\n",
            "Epoch: 173 [100/100]\tIteration: 17400\tLoss: 0.379349\tAccuracy: 75.90 +- 1.06 %\n",
            "\n",
            "Loss: 2.026194\tAccuracy: 42.00 +- 0.83 %\n",
            "\n",
            "Epoch: 176 [100/100]\tIteration: 17700\tLoss: 0.520626\tAccuracy: 76.44 +- 1.08 %\n",
            "Epoch: 179 [100/100]\tIteration: 18000\tLoss: 0.703483\tAccuracy: 76.82 +- 1.03 %\n",
            "\n",
            "Loss: 1.964661\tAccuracy: 41.41 +- 0.82 %\n",
            "\n",
            "Epoch: 182 [100/100]\tIteration: 18300\tLoss: 0.531747\tAccuracy: 77.65 +- 1.07 %\n",
            "Epoch: 185 [100/100]\tIteration: 18600\tLoss: 0.502843\tAccuracy: 77.29 +- 1.06 %\n",
            "\n",
            "Loss: 2.010159\tAccuracy: 40.99 +- 0.83 %\n",
            "\n",
            "Epoch: 188 [100/100]\tIteration: 18900\tLoss: 0.361460\tAccuracy: 77.27 +- 1.04 %\n",
            "Epoch: 191 [100/100]\tIteration: 19200\tLoss: 0.491305\tAccuracy: 77.58 +- 1.02 %\n",
            "\n",
            "Loss: 1.975358\tAccuracy: 41.79 +- 0.85 %\n",
            "\n",
            "Epoch: 194 [100/100]\tIteration: 19500\tLoss: 0.907579\tAccuracy: 77.68 +- 1.09 %\n",
            "Epoch: 197 [100/100]\tIteration: 19800\tLoss: 0.336908\tAccuracy: 78.68 +- 1.03 %\n",
            "\n",
            "Loss: 2.073196\tAccuracy: 42.19 +- 0.85 %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r /content/drive/MyDrive/DLCV/HW4/p1_models/15600-protonet.pth /content/"
      ],
      "metadata": {
        "id": "C1ZizWQJdtfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from argparse import Namespace\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)\n",
        "\n",
        "# fix random seeds for reproducibility\n",
        "SEED = 123\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "class Convnet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(in_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    bn = nn.BatchNorm2d(out_channels)\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        bn,\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "class Protonet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.conv = Convnet(in_channels, hid_channels, out_channels)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(1600, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 400)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "def worker_init_fn(worker_id):                                                          \n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "\n",
        "# mini-Imagenet dataset\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "class GeneratorSampler(Sampler):\n",
        "    def __init__(self, episode_file_path):\n",
        "        episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\n",
        "        self.sampled_sequence = episode_df.values.flatten().tolist()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.sampled_sequence) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sampled_sequence)\n",
        "\n",
        "def pairwise_distances(x, y, matching_fn='parametric', parametric=None):\n",
        "    n_x = x.shape[0]\n",
        "    n_y = y.shape[0]\n",
        "    x_exp = x.unsqueeze(1).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "    y_exp = y.unsqueeze(0).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "    \n",
        "    distances = parametric(torch.cat([x_exp, y_exp], dim=-1))\n",
        "    \n",
        "    return distances.reshape(n_x, n_y)\n",
        "\n",
        "def predict(args, model, data_loader):\n",
        "    for _, m in model.items():\n",
        "        m.eval()\n",
        "\n",
        "    prediction_results = []\n",
        "    episodic_acc = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # each batch represent one episode (support data + query data)\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            data = data.cuda()\n",
        "            # split data into support and query data\n",
        "            support_input = data[:args.N_way * args.N_shot,:,:,:] \n",
        "            query_input   = data[args.N_way * args.N_shot:,:,:,:]\n",
        "\n",
        "            # create the relative label (0 ~ N_way-1) for query data\n",
        "            # label_encoder = {target[i * args.N_shot] : i for i in range(args.N_way)}\n",
        "            # query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[args.N_way * args.N_shot:]])\n",
        "\n",
        "            #  extract the feature of support and query data\n",
        "            support = model['proto'](support_input)\n",
        "            queries = model['proto'](query_input)\n",
        "\n",
        "            #  calculate the prototype for each class according to its support data\n",
        "            prototypes = support.reshape(args.N_way, args.N_shot, -1).mean(dim=1)\n",
        "            distances = pairwise_distances(queries, prototypes, args.matching_fn, model['parametric'])\n",
        "\n",
        "            #  classify the query data depending on the its distense with each prototype\n",
        "            y_pred = (-distances).softmax(dim=1).max(1, keepdim=True)[1]\n",
        "            prediction_results.append(y_pred.reshape(-1))\n",
        "\n",
        "    return prediction_results\n",
        "\n",
        "def parse_args():\n",
        "    # parser = argparse.ArgumentParser(description=\"Few shot learning\")\n",
        "    # parser.add_argument('--N-way', default=5, type=int, help='N_way (default: 5)')\n",
        "    # parser.add_argument('--N-shot', default=1, type=int, help='N_shot (default: 1)')\n",
        "    # parser.add_argument('--N-query', default=15, type=int, help='N_query (default: 15)')\n",
        "    # parser.add_argument('--M_aug', default=10, type=int, help='M_augmentation (default: 10)')\n",
        "    # parser.add_argument('--matching_fn', default='parametric', type=str, help='distance matching function')\n",
        "    # parser.add_argument('--load', type=str, help=\"Model checkpoint path\")\n",
        "    # parser.add_argument('--test_csv', default='/content/hw4_data/mini/val.csv', type=str, help=\"Testing images csv file\")\n",
        "    # parser.add_argument('--test_data_dir', default='/content/hw4_data/mini/val', type=str, help=\"Testing images directory\")\n",
        "    # parser.add_argument('--testcase_csv', default='/content/hw4_data/mini/val_testcase.csv', type=str, help=\"Test case csv\")\n",
        "    # parser.add_argument('--output_csv', type=str, help=\"Output filename\")\n",
        "\n",
        "    # return parser.parse_args()\n",
        "    parameter = {\n",
        "        'N_way': 5,\n",
        "        'N_shot': 1,\n",
        "        'N_query': 15,\n",
        "        'M_aug': 10,\n",
        "        'matching_fn': 'parametric',  #cosine parametric l2\n",
        "        'load': '/content/15600-protonet.pth',\n",
        "        'test_csv': '/content/hw4_data/mini/val.csv',\n",
        "        'test_data_dir': '/content/hw4_data/mini/val',\n",
        "        'testcase_csv': '/content/hw4_data/mini/val_testcase.csv',\n",
        "        'output_csv': './output2.csv',\n",
        "    }\n",
        "    config = Namespace(**parameter)\n",
        "    return config\n",
        "\n",
        "if __name__=='__main__':\n",
        "    args = parse_args()\n",
        "\n",
        "    test_dataset = MiniDataset(args.test_csv, args.test_data_dir)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=args.N_way * (args.N_query + args.N_shot),\n",
        "        num_workers=3, pin_memory=False, worker_init_fn=worker_init_fn,\n",
        "        sampler=GeneratorSampler(args.testcase_csv))\n",
        "\n",
        "    # TODO: load your model\n",
        "    state = torch.load(args.load)\n",
        "    model = {}\n",
        "    model['proto'] = Protonet().cuda()\n",
        "    model['proto'].load_state_dict(state['state_dict'])\n",
        "    model['parametric'] = nn.Sequential(\n",
        "        nn.Linear(800, 400),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(400, 1)\n",
        "    ).cuda()\n",
        "    model['parametric'].load_state_dict(state['parametric'])\n",
        "\n",
        "    prediction_results = predict(args, model, test_loader)\n",
        "\n",
        "    if os.path.dirname(args.output_csv):\n",
        "        os.makedirs(os.path.dirname(args.output_csv), exist_ok=True)\n",
        "    # TODO: output your prediction to csv\n",
        "    with open(args.output_csv, 'w') as out_file:\n",
        "        line = 'episode_id'\n",
        "        for i in range(args.N_way*args.N_query):\n",
        "            line += ',query%d' % (i)\n",
        "        line += '\\n'\n",
        "        out_file.write(line)\n",
        "\n",
        "        for i, prediction in enumerate(prediction_results):\n",
        "            line = '%d' % (i)\n",
        "            for j in prediction:\n",
        "                line += ',%d' % j\n",
        "            line += '\\n'\n",
        "            out_file.write(line)\n",
        "\n",
        "#Reference: https://github.com/kai860115/DLCV2020-FALL/tree/main/hw4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "976IZYxBd49P",
        "outputId": "614229fd-5466-4784-f20f-cf835fd021df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, csv\n",
        "import numpy as np\n",
        "path1 = '/content/output2.csv'\n",
        "path2 = '/content/hw4_data/mini/val_testcase_gt.csv'\n",
        "\n",
        "# read your prediction file\n",
        "with open(path1, mode='r') as pred:\n",
        "    reader = csv.reader(pred)\n",
        "    next(reader, None)  # skip the headers\n",
        "    pred_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\n",
        "\n",
        "# read ground truth data\n",
        "with open(path2, mode='r') as gt:\n",
        "    reader = csv.reader(gt)\n",
        "    next(reader, None)  # skip the headers\n",
        "    gt_dict = {int(rows[0]): np.array(rows[1:]).astype(int) for rows in reader}\n",
        "\n",
        "if len(pred_dict) != len(gt_dict):\n",
        "    sys.exit(\"Test case length mismatch.\")\n",
        "\n",
        "episodic_acc = []\n",
        "for key, value in pred_dict.items():\n",
        "    if key not in gt_dict:\n",
        "        sys.exit(\"Episodic id mismatch: \\\"{}\\\" does not exist in the provided ground truth file.\".format(key))\n",
        "\n",
        "    episodic_acc.append((gt_dict[key] == value).mean().item())\n",
        "\n",
        "episodic_acc = np.array(episodic_acc)\n",
        "mean = episodic_acc.mean()\n",
        "std = episodic_acc.std()\n",
        "\n",
        "print('Accuracy: {:.2f} +- {:.2f} %'.format(mean * 100, 1.96 * std / (600)**(1/2) * 100))"
      ],
      "metadata": {
        "id": "yATT4FKqd6Tr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a183b91f-094a-43de-ed21-546df48abb47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 43.99 +- 0.83 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from argparse import Namespace\n",
        "\n",
        "from PIL import Image\n",
        "filenameToPILImage = lambda x: Image.open(x)\n",
        "\n",
        "# fix random seeds for reproducibility\n",
        "SEED = 123\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "class Convnet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            conv_block(in_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, hid_channels),\n",
        "            conv_block(hid_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x.view(x.size(0), -1)\n",
        "\n",
        "def conv_block(in_channels, out_channels):\n",
        "    bn = nn.BatchNorm2d(out_channels)\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "        bn,\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "\n",
        "class Protonet(nn.Module):\n",
        "    def __init__(self, in_channels=3, hid_channels=64, out_channels=64):\n",
        "        super().__init__()\n",
        "        self.conv = Convnet(in_channels, hid_channels, out_channels)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(1600, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 800),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(800, 400)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "def worker_init_fn(worker_id):                                                          \n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "\n",
        "# mini-Imagenet dataset\n",
        "class MiniDataset(Dataset):\n",
        "    def __init__(self, csv_path, data_dir):\n",
        "        self.data_dir = data_dir\n",
        "        self.data_df = pd.read_csv(csv_path).set_index(\"id\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            filenameToPILImage,\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.data_df.loc[index, \"filename\"]\n",
        "        label = self.data_df.loc[index, \"label\"]\n",
        "        image = self.transform(os.path.join(self.data_dir, path))\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "class GeneratorSampler(Sampler):\n",
        "    def __init__(self, episode_file_path):\n",
        "        episode_df = pd.read_csv(episode_file_path).set_index(\"episode_id\")\n",
        "        self.sampled_sequence = episode_df.values.flatten().tolist()\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(self.sampled_sequence) \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sampled_sequence)\n",
        "\n",
        "def pairwise_distances(x, y, matching_fn='l2', parametric=None):\n",
        "    n_x = x.shape[0]\n",
        "    n_y = y.shape[0]\n",
        "\n",
        "    if matching_fn == 'l2':\n",
        "        distances = (\n",
        "                x.unsqueeze(1).expand(n_x, n_y, -1) -\n",
        "                y.unsqueeze(0).expand(n_x, n_y, -1)\n",
        "        ).pow(2).sum(dim=2)\n",
        "        return distances\n",
        "    elif matching_fn == 'cosine':\n",
        "        cos = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
        "        cosine_similarities = cos(x.unsqueeze(1).expand(n_x, n_y, -1), y.unsqueeze(0).expand(n_x, n_y, -1))\n",
        "\n",
        "        return 1 - cosine_similarities\n",
        "    elif matching_fn == 'parametric':\n",
        "        x_exp = x.unsqueeze(1).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "        y_exp = y.unsqueeze(0).expand(n_x, n_y, -1).reshape(n_x*n_y, -1)\n",
        "        \n",
        "        distances = parametric(torch.cat([x_exp, y_exp], dim=-1))\n",
        "        \n",
        "        return distances.reshape(n_x, n_y)\n",
        "\n",
        "    else:\n",
        "        raise(ValueError('Unsupported similarity function'))\n",
        "\n",
        "def predict(args, model, data_loader):\n",
        "    for _, m in model.items():\n",
        "        m.eval()\n",
        "\n",
        "    prediction_results = []\n",
        "    episodic_acc = []\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # each batch represent one episode (support data + query data)\n",
        "        for i, (data, target) in enumerate(data_loader):\n",
        "            data = data.cuda()\n",
        "            # split data into support and query data\n",
        "            support_input = data[:args.N_way * args.N_shot,:,:,:] \n",
        "            query_input   = data[args.N_way * args.N_shot:,:,:,:]\n",
        "\n",
        "            # create the relative label (0 ~ N_way-1) for query data\n",
        "            # label_encoder = {target[i * args.N_shot] : i for i in range(args.N_way)}\n",
        "            # query_label = torch.cuda.LongTensor([label_encoder[class_name] for class_name in target[args.N_way * args.N_shot:]])\n",
        "\n",
        "            #  extract the feature of support and query data\n",
        "            if args.type == 'proto':\n",
        "                support = model['proto'](support_input)\n",
        "                queries = model['proto'](query_input)\n",
        "\n",
        "                #  calculate the prototype for each class according to its support data\n",
        "                prototypes = support.reshape(args.N_way, args.N_shot, -1).mean(dim=1)\n",
        "\n",
        "            if args.matching_fn == 'parametric':\n",
        "                distances = pairwise_distances(queries, prototypes, args.matching_fn, model['parametric'])\n",
        "            else:\n",
        "                distances = pairwise_distances(queries, prototypes, args.matching_fn)\n",
        "\n",
        "            else:\n",
        "                support = model['cnn'](support_input)\n",
        "                queries = model['cnn'](query_input)\n",
        "\n",
        "                sample_idx = torch.tensor([torch.randint(args.N_shot * i, args.N_shot * (i + 1), (args.M_aug,)).numpy() for i in range(args.N_way)]).reshape(-1)\n",
        "                sample = support[sample_idx]\n",
        "                noise = torch.randn(sample.shape).cuda()\n",
        "\n",
        "                support_g = model['g'](sample, noise).reshape(args.N_way, args.M_aug, -1)\n",
        "                support = support.reshape(args.N_way, args.N_shot, -1)\n",
        "\n",
        "                support_aug = torch.cat([support, support_g], dim=1)\n",
        "                support_aug = support_aug.reshape(args.N_way * (args.N_shot + args.M_aug), -1)\n",
        "\n",
        "                prototypes = model['mlp'](support_aug)\n",
        "                prototypes = prototypes.reshape(args.N_way, args.N_shot + args.M_aug, -1).mean(dim=1)\n",
        "                queries = model['mlp'](queries)\n",
        "\n",
        "                distances = pairwise_distances(queries, prototypes, args.matching_fn)\n",
        "\n",
        "            #  classify the query data depending on the its distense with each prototype\n",
        "            y_pred = (-distances).softmax(dim=1).max(1, keepdim=True)[1]\n",
        "            prediction_results.append(y_pred.reshape(-1))\n",
        "\n",
        "    return prediction_results\n",
        "\n",
        "def parse_args():\n",
        "    # parser = argparse.ArgumentParser(description=\"Few shot learning\")\n",
        "    # parser.add_argument('--N-way', default=5, type=int, help='N_way (default: 5)')\n",
        "    # parser.add_argument('--N-shot', default=1, type=int, help='N_shot (default: 1)')\n",
        "    # parser.add_argument('--N-query', default=15, type=int, help='N_query (default: 15)')\n",
        "    # parser.add_argument('--M_aug', default=10, type=int, help='M_augmentation (default: 10)')\n",
        "    # parser.add_argument('--matching_fn', default='l2', type=str, help='distance matching function')\n",
        "    # parser.add_argument('--load', type=str, help=\"Model checkpoint path\")\n",
        "    # parser.add_argument('--type', type=str, choices=['proto', 'dhm', 'improved'], help=\"Model type\")\n",
        "    # parser.add_argument('--test_csv', default='./hw4_data/val.csv', type=str, help=\"Testing images csv file\")\n",
        "    # parser.add_argument('--test_data_dir', default='./hw4_data/val', type=str, help=\"Testing images directory\")\n",
        "    # parser.add_argument('--testcase_csv', default='./hw4_data/val_testcase.csv', type=str, help=\"Test case csv\")\n",
        "    # parser.add_argument('--output_csv', type=str, help=\"Output filename\")\n",
        "\n",
        "    # return parser.parse_args()\n",
        "    parameter = {\n",
        "        'N_way': 5,\n",
        "        'N_shot': 1,\n",
        "        'N_query': 15,\n",
        "        'M_aug': 10,\n",
        "        'matching_fn': 'parametric',#cosine parametric l2\n",
        "        'load': '/content/15600-protonet.pth',\n",
        "        # 'type': 'proto',\n",
        "        'test_csv': '/content/hw4_data/mini/val.csv',\n",
        "        'test_data_dir': '/content/hw4_data/mini/val',\n",
        "        'testcase_csv': '/content/hw4_data/mini/val_testcase.csv',\n",
        "        'output_csv': './output6.csv',\n",
        "    }\n",
        "    config = Namespace(**parameter)\n",
        "    return config\n",
        "\n",
        "if __name__=='__main__':\n",
        "    args = parse_args()\n",
        "\n",
        "    test_dataset = MiniDataset(args.test_csv, args.test_data_dir)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=args.N_way * (args.N_query + args.N_shot),\n",
        "        num_workers=3, pin_memory=False, worker_init_fn=worker_init_fn,\n",
        "        sampler=GeneratorSampler(args.testcase_csv))\n",
        "\n",
        "    # TODO: load your model\n",
        "    state = torch.load(args.load)\n",
        "    model = {}\n",
        "    if args.type == 'proto':\n",
        "        from prototypical_net.model import Protonet\n",
        "        model['proto'] = Protonet().cuda()\n",
        "        model['proto'].load_state_dict(state['state_dict'])\n",
        "\n",
        "    if args.matching_fn == 'parametric':\n",
        "        model['parametric'] = nn.Sequential(\n",
        "            nn.Linear(800, 400),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(400, 1)\n",
        "        ).cuda()\n",
        "        model['parametric'].load_state_dict(state['parametric'])\n",
        "    \n",
        "    else:\n",
        "        if args.type == 'dhm':\n",
        "            from data_hallucination.model import Convnet, Hallucinator, MLP\n",
        "        elif args.type == 'improved':\n",
        "            from improved_data_hallucination.model import Convnet, Hallucinator, MLP\n",
        "\n",
        "        model['cnn'] = Convnet().cuda()\n",
        "        model['cnn'].load_state_dict(state['cnn'])\n",
        "        model['g'] = Hallucinator().cuda()\n",
        "        model['g'].load_state_dict(state['g'])\n",
        "        model['mlp'] = MLP().cuda()\n",
        "        model['mlp'].load_state_dict(state['mlp'])\n",
        "\n",
        "    prediction_results = predict(args, model, test_loader)\n",
        "\n",
        "    if os.path.dirname(args.output_csv):\n",
        "        os.makedirs(os.path.dirname(args.output_csv), exist_ok=True)\n",
        "    # TODO: output your prediction to csv\n",
        "    with open(args.output_csv, 'w') as out_file:\n",
        "        line = 'episode_id'\n",
        "        for i in range(args.N_way*args.N_query):\n",
        "            line += ',query%d' % (i)\n",
        "        line += '\\n'\n",
        "        out_file.write(line)\n",
        "\n",
        "        for i, prediction in enumerate(prediction_results):\n",
        "            line = '%d' % (i)\n",
        "            for j in prediction:\n",
        "                line += ',%d' % j\n",
        "            line += '\\n'\n",
        "            out_file.write(line)"
      ],
      "metadata": {
        "id": "r46sINxjfbzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp -r /content/ckpt_cos/15600-protonet.pth /content/drive/MyDrive/DLCV/HW4/p1_models"
      ],
      "metadata": {
        "id": "xDUy8oI5z3_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rreference: https://github.com/kai860115/DLCV2020-FALL/tree/main/hw4"
      ],
      "metadata": {
        "id": "zol5c6EWazlG"
      }
    }
  ]
}